# SPDX-FileCopyrightText: Copyright (c) 2024-2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: BSD 2-Clause License

"""Unit tests for the Animation Graph Service."""

import asyncio
import time
from http import HTTPStatus
from pathlib import Path
from typing import Any
from unittest.mock import ANY, AsyncMock, MagicMock, patch

import pytest
import yaml
from loguru import logger
from pipecat.frames.frames import ErrorFrame, StartInterruptionFrame, TextFrame
from pipecat.pipeline.pipeline import Pipeline
from pipecat.pipeline.task import PipelineTask

from nvidia_pipecat.frames.action import (
    FinishedGestureBotActionFrame,
    FinishedPostureBotActionFrame,
    StartedGestureBotActionFrame,
    StartedPostureBotActionFrame,
    StartGestureBotActionFrame,
    StartPostureBotActionFrame,
    StopPostureBotActionFrame,
)
from nvidia_pipecat.frames.animation import (
    AnimationDataStreamRawFrame,
    AnimationDataStreamStartedFrame,
    AnimationDataStreamStoppedFrame,
)
from nvidia_pipecat.services.animation_graph_service import (
    AnimationGraphConfiguration,
    AnimationGraphService,
)
from nvidia_pipecat.utils.logging import setup_default_ace_logging
from nvidia_pipecat.utils.message_broker import MessageBrokerConfig
from tests.unit.utils import FrameStorage, ignore, run_interactive_test


def load_yaml(path: Path) -> dict[str, Any]:
    """Load YAML configuration from a file.

    Args:
        path: Path to the YAML file.

    Returns:
        dict: Parsed YAML content.

    Raises:
        FileNotFoundError: If the YAML file is not found.
    """
    try:
        return yaml.safe_load(path.read_text())

    except FileNotFoundError as error:
        message = "Error: yml config file not found."
        logger.exception(message)
        raise FileNotFoundError(error, message) from error


def read_action_service_config(config_path: Path) -> AnimationGraphConfiguration:
    """Read and parse the animation graph service configuration.

    Args:
        config_path: Path to the configuration YAML file.

    Returns:
        AnimationGraphConfiguration: Parsed configuration object.
    """
    return AnimationGraphConfiguration(**load_yaml(config_path))


looping_animations_to_test = [
    ("listening", "Listening"),
    ("thinking about something", "Thinking"),
    ("dancing", "Listening"),
]


class MockResponse:
    """Mock HTTP response for testing animation graph service REST endpoints."""

    def __init__(self):
        """Initialize mock response with default status and headers."""
        self.status = HTTPStatus.OK
        self.headers = {"Content-Type": "application/json"}

    async def json(self):
        """Simulate async JSON response.

        Returns:
            dict: Mock response data.
        """
        await asyncio.sleep(0.1)
        return {"response": "OK"}


@pytest.fixture
def anim_graph():
    """Create and configure an Animation Graph Service instance for testing.

    Returns:
        AnimationGraphService: Configured service instance with test configuration.
    """
    animation_config = read_action_service_config(Path("./tests/unit/configs/animation_config.yaml"))
    message_broker_config = MessageBrokerConfig("local_queue", "")

    logger.info("Starting animation graph service initialization...")
    start_time = time.time()
    AnimationGraphService.pregenerate_animation_databases(animation_config)
    init_time = time.time() - start_time
    logger.info(f"Animation graph service initialized in {init_time * 1000:.2f}ms")

    ag = AnimationGraphService(
        animation_graph_rest_url="http://127.0.0.1:8020",
        animation_graph_grpc_target="127.0.0.1:51000",
        message_broker_config=message_broker_config,
        config=animation_config,
    )

    return ag


@pytest.mark.asyncio
@pytest.mark.parametrize("posture", looping_animations_to_test)
@patch("aiohttp.ClientSession.request")
async def test_simple_posture_pipeline(mock_get, posture, anim_graph):
    """Test basic posture pipeline functionality.

    Verifies that the pipeline correctly processes posture commands and
    generates appropriate animation frames.

    Args:
        mock_get: Mock for HTTP client requests.
        posture: Tuple of (natural language description, clip ID) for testing.
        anim_graph: Animation graph service fixture.
    """
    posture_nld, posture_clip_id = posture
    stream_id = "1235"

    # Mocking response from aiohttp.ClientSession.request
    mock_get.return_value.__aenter__.return_value = MockResponse()

    after_storage = FrameStorage()
    before_storage = FrameStorage()
    pipeline = Pipeline([before_storage, anim_graph, after_storage])

    async def test_routine(task: PipelineTask):
        # send events
        await task.queue_frame(TextFrame("Hello"))
        await task.queue_frame(StartPostureBotActionFrame(posture=posture_nld, action_id="posture_1"))

        # wait for the action to start
        started_posture_frame = ignore(StartedPostureBotActionFrame(action_id="posture_1"), "ids", "timestamps")
        await after_storage.wait_for_frame(started_posture_frame)

        # Ensure API endpoints was called in the right way
        mock_get.assert_called_once_with(
            "put",
            f"http://127.0.0.1:8020/streams/{stream_id}/animation_graphs/avatar/variables/posture_state/{posture_clip_id}",
            data="{}",
            headers={"Content-Type": "application/json", "x-stream-id": stream_id},
            params={},
        )
        # ensure we got the text frame as well as a presence started event (and no finished)
        assert after_storage.history[1].frame == ignore(TextFrame("Hello"), "all_ids", "timestamps")
        assert after_storage.history[3].frame == started_posture_frame
        assert len(after_storage.frames_of_type(FinishedPostureBotActionFrame)) == 0

        # stop the action and wait for it to finish
        finished_posture_frame = FinishedPostureBotActionFrame(
            action_id="posture_1", is_success=True, was_stopped=True, failure_reason=""
        )
        await task.queue_frame(StopPostureBotActionFrame(action_id="posture_1"))
        await after_storage.wait_for_frame(ignore(finished_posture_frame, "ids", "timestamps"))
        await before_storage.wait_for_frame(ignore(finished_posture_frame, "ids", "timestamps"))

        # make sure observed frames before and after the processor match
        # (this should be true for all action frame processors)
        assert len(before_storage.history) == len(after_storage.history)
        for before, after in zip(before_storage.history, after_storage.history, strict=False):
            assert before.frame == after.frame

    await run_interactive_test(pipeline, test_coroutine=test_routine, start_metadata={"stream_id": stream_id})


@pytest.mark.asyncio
@patch("aiohttp.ClientSession.request")
async def test_finite_animation(mock_get, anim_graph):
    """Test finite animation execution and completion.

    Verifies that a finite animation:
    - Starts correctly
    - Runs for the expected duration
    - Completes with proper frame sequence
    """
    # Mocking response from aiohttp.ClientSession.request
    mock_get.return_value.__aenter__.return_value = MockResponse()

    storage = FrameStorage()
    pipeline = Pipeline([anim_graph, storage])

    async def test_routine(task: PipelineTask):
        # send events
        await task.queue_frame(StartGestureBotActionFrame(gesture="Test", action_id="g1"))

        # wait for the action to start
        started_gesture_frame = StartedGestureBotActionFrame(action_id="g1")
        await storage.wait_for_frame(ignore(started_gesture_frame, "ids", "timestamps"))
        assert len(storage.frames_of_type(FinishedGestureBotActionFrame)) == 0

        # Action should not be finished
        await asyncio.sleep(0.3)
        assert len(storage.frames_of_type(FinishedGestureBotActionFrame)) == 0

        # Action should now be done
        await asyncio.sleep(0.3)
        assert len(storage.frames_of_type(FinishedGestureBotActionFrame)) == 1

    await run_interactive_test(pipeline, test_coroutine=test_routine, start_metadata={"stream_id": "1235"})


@pytest.mark.asyncio
@patch("aiohttp.ClientSession.request")
async def test_consecutive_postures(mock_get, anim_graph):
    """Test handling of consecutive posture commands.

    Verifies that the service correctly:
    - Processes multiple posture commands in sequence
    - Transitions between postures smoothly
    - Maintains correct frame order and state
    """
    # Mocking response from aiohttp.ClientSession.request
    mock_get.return_value.__aenter__.return_value = MockResponse()

    stream_id = "1235"
    setup_default_ace_logging(stream_id=stream_id, level="TRACE")

    after_storage = FrameStorage()
    before_storage = FrameStorage()
    pipeline = Pipeline([before_storage, anim_graph, after_storage])

    async def test_routine(task: PipelineTask):
        # start first posture
        await task.queue_frame(StartPostureBotActionFrame(posture="talking", action_id="posture_1"))

        # wait for first posture to start
        started_posture_1_frame = ignore(StartedPostureBotActionFrame(action_id="posture_1"), "ids", "timestamps")
        assert started_posture_1_frame.action_id == "posture_1"
        await after_storage.wait_for_frame(started_posture_1_frame)

        # start second posture
        await task.queue_frame(StartPostureBotActionFrame(posture="listening", action_id="posture_2"))

        # wait for second posture to start
        started_posture_2_frame = ignore(StartedPostureBotActionFrame(action_id="posture_2"), "ids", "timestamps")
        assert started_posture_2_frame.action_id == "posture_2"
        await after_storage.wait_for_frame(started_posture_2_frame)

        # Ensure API endpoints was called twice
        assert mock_get.call_count == 2

        # ensure we got the text frame as well as a presence started event (and no finished)
        assert after_storage.history[2].frame == started_posture_1_frame
        assert after_storage.history[4].frame == ignore(
            FinishedPostureBotActionFrame(
                action_id="posture_1", is_success=False, was_stopped=False, failure_reason="Action replaced."
            ),
            "ids",
            "timestamps",
        )
        assert after_storage.history[5].frame == started_posture_2_frame
        assert len(after_storage.frames_of_type(FinishedPostureBotActionFrame)) == 1

        # make sure observed frames before and after the processor match
        assert len(before_storage.history) == len(after_storage.history)
        for before, after in zip(before_storage.history, after_storage.history, strict=False):
            assert before.frame == after.frame

    await run_interactive_test(pipeline, test_coroutine=test_routine, start_metadata={"stream_id": stream_id})


@pytest.mark.asyncio
@patch("aiohttp.ClientSession.request")
async def test_immediate_stop_posture(mock_get, anim_graph):
    """Test immediate posture cancellation.

    Verifies that the service correctly handles immediate posture cancellation:
    - Processes stop command immediately after start
    - Generates appropriate failure frames
    - Maintains correct frame sequence
    """
    # Mocking response from aiohttp.ClientSession.request
    mock_get.return_value.__aenter__.return_value = MockResponse()

    stream_id = "1235"
    setup_default_ace_logging(stream_id=stream_id, level="TRACE")

    after_storage = FrameStorage()
    before_storage = FrameStorage()
    pipeline = Pipeline([before_storage, anim_graph, after_storage])

    async def test_routine(task: PipelineTask):
        # start/stop first posture
        start_posture_1_frame = StartPostureBotActionFrame(posture="talking", action_id="posture_1")
        stop_posture_1_frame = StopPostureBotActionFrame(action_id="posture_1")
        await task.queue_frames([start_posture_1_frame, stop_posture_1_frame])

        # wait for first posture to finish
        finished_posture_1_frame = ignore(
            FinishedPostureBotActionFrame(
                action_id="posture_1", was_stopped=True, is_success=False, failure_reason=ANY
            ),
            "ids",
            "timestamps",
        )
        await after_storage.wait_for_frame(finished_posture_1_frame)

        # check for the correct frame sequence
        assert after_storage.history[-2].frame == ignore(stop_posture_1_frame, "ids", "timestamps")
        assert after_storage.history[-1].frame == finished_posture_1_frame

        # make sure observed frames before and after the processor match
        assert len(before_storage.history) == len(after_storage.history)
        for before, after in zip(before_storage.history, after_storage.history, strict=True):
            assert before.frame == after.frame

    await run_interactive_test(pipeline, test_coroutine=test_routine, start_metadata={"stream_id": stream_id})


@pytest.mark.asyncio
@patch("aiohttp.ClientSession.request")
async def test_stacking_postures_with_interruptions(mock_get, anim_graph):
    """Test stacking postures with interruptions.

    In this test we reproduce a bug that was observed where the override statemachine
    would sometimes fail if we start many postures at the same time and also
    have interruptions.
    """
    # Mocking response from aiohttp.ClientSession.request
    mock_get.return_value.__aenter__.return_value = MockResponse()

    stream_id = "1235"
    setup_default_ace_logging(stream_id=stream_id, level="TRACE")

    after_storage = FrameStorage()
    before_storage = FrameStorage()
    pipeline = Pipeline([before_storage, anim_graph, after_storage])

    async def test_routine(task: PipelineTask):
        N = 200
        for i in range(N):
            await task.queue_frame(StartPostureBotActionFrame(posture="talking", action_id=f"posture_{i}"))
            await asyncio.sleep(0.05)
            if i == 5:
                await task.queue_frame(StartInterruptionFrame())

        final_posture_started = ignore(StartedPostureBotActionFrame(action_id=f"posture_{N - 1}"), "ids", "timestamps")
        await after_storage.wait_for_frame(final_posture_started)

        assert len(after_storage.frames_of_type(FinishedPostureBotActionFrame)) == N - 1

    await run_interactive_test(pipeline, test_coroutine=test_routine, start_metadata={"stream_id": stream_id})


@patch("aiohttp.ClientSession.request")
async def test_handling_animation_data(mock_get, anim_graph):
    """Test animation data stream processing.

    Verifies that the service correctly:
    - Handles animation data stream frames
    - Processes animation data in correct sequence
    - Maintains proper timing between frames
    """
    # Mocking response from aiohttp.ClientSession.request
    mock_get.return_value.__aenter__.return_value = MockResponse()

    # Mocking gRPC stream
    mock_stub = MagicMock()
    stream_mock = AsyncMock()
    stream_mock.write.return_value = "OK"
    stream_mock.done = MagicMock(return_value=False)  #
    mock_stub.PushAnimationDataStream.return_value = stream_mock

    stream_id = "1235"
    anim_graph.stub = mock_stub
    storage = FrameStorage()
    pipeline = Pipeline([anim_graph, storage])

    async def test_routine(task: PipelineTask):
        # send events
        await task.queue_frame(
            AnimationDataStreamStartedFrame(
                audio_header=None, animation_header=None, action_id="a1", animation_source_id="test"
            )
        )

        for _ in range(5):
            await task.queue_frame(AnimationDataStreamRawFrame(animation_data={}, action_id="a1"))
            await asyncio.sleep(1.0 / 30.0)

        await task.queue_frame(AnimationDataStreamStoppedFrame(action_id="a1"))

    await run_interactive_test(pipeline, test_coroutine=test_routine, start_metadata={"stream_id": stream_id})


@patch("aiohttp.ClientSession.request")
async def test_handling_low_fps_animation_data(mock_get, anim_graph):
    """Test animation data stream processing with low FPS.

    Verifies that the service correctly sends out an
    ErrorFrame when the animation data received is below 30 FPS.
    """
    # Mocking response from aiohttp.ClientSession.request
    mock_get.return_value.__aenter__.return_value = MockResponse()

    # Mocking gRPC stream
    mock_stub = MagicMock()
    stream_mock = AsyncMock()
    stream_mock.write.return_value = "OK"
    stream_mock.done = MagicMock(return_value=False)  #
    mock_stub.PushAnimationDataStream.return_value = stream_mock

    stream_id = "1235"
    anim_graph.stub = mock_stub
    storage = FrameStorage()
    pipeline = Pipeline([anim_graph, storage])

    async def test_routine(task: PipelineTask):
        # send events
        await task.queue_frame(
            AnimationDataStreamStartedFrame(
                audio_header=None, animation_header=None, action_id="a1", animation_source_id="test"
            )
        )

        for _ in range(20):
            await task.queue_frame(AnimationDataStreamRawFrame(animation_data={}, action_id="a1"))
            await asyncio.sleep(1.0 / 24.5)

        await task.queue_frame(AnimationDataStreamStoppedFrame(action_id="a1"))

        await storage.wait_for_frame(
            ignore(ErrorFrame(error="Animgraph: Low FPS detected: 24FPS (below 30 FPS).", fatal=False), "ids", "error")
        )

    await run_interactive_test(pipeline, test_coroutine=test_routine, start_metadata={"stream_id": stream_id})


@pytest.mark.asyncio
async def test_animation_database_search(anim_graph):
    """Test animation database semantic search functionality.

    Verifies that searching for 'wave to the user' correctly returns the 'Goodbye'
    animation clip with appropriate semantic match scores.
    """
    # Get the gesture animation database
    gesture_db = AnimationGraphService.animation_databases["gesture"]

    # Search for the animation
    match = gesture_db.query_one("wave goodbye to the user somehow")

    # Verify we got a match and it's the Goodbye animation
    assert match.animation.id == "Goodbye", "Expected 'wave to the user' to map to 'Goodbye' animation"
    assert match.description_score > 0.5 or match.meaning_score > 0.5, "Expected high semantic match score"
